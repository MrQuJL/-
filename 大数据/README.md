# 大数据

## Map-Reduce和Hadoop逐渐成为面试热门

## 介绍哈希函数

* 哈希函数又叫散列函数，哈希函数的输入域可以是非常大的范围，但是输出域是固定的范围。假设为s。
	
	1. 典型的哈希函数都拥有无限的输入值域。
	2. 输入值相同时，返回值（哈希值）一样。
	3. 输入值不同时，返回值（哈希值）可能一样，也可能不一样。
	4. 不同输入值得到的哈希值，整体均匀的分布在输出域s上。（重要）

* 1~3点性质是哈希函数的基础，第4点是评价一个哈希函数优劣的关键。

* 不同输入值得到的哈希值越均匀分布在s上，该哈希函数越优秀。

* MD5与SHA1算法都是经典的哈希函数算法，了解即可，面试时不要求掌握。

## 介绍Map-Reduce

1. Map阶段 --> （通过Hash分段的方式，哈希函数可以是系统默认的也可以是自定义的）把大任务分成子任务。
	
	* 同样Hash值的任务会被分到一个节点上进行处理，在分布式系统中，一个节点可能是一台机器，也可能是一个计算节点。

	* 在Map阶段可以对每一个子任务计算出一些结果，合并的时候把这些结果按照用户指定的要求做一些处理即可。

2. Reduce阶段 --> 子任务并发处理，然后合并结果。

## Map-Reduce的难点

* 工程上的处理

* 在一个大型的分布式系统中，每台机器假定是一个计算节点，这么多机器总会有坏的，一旦坏了，怎么办呢？

* 注意点：

	1. 备份的考虑，分布式存储的设计细节，以及容灾策略。

	2. 一份数据需要多少个副本节点来进行备份呢？（这是需要考虑的）

	3. Map-Reduce产生的文件相当庞大，一个文件就可能让一台机器存不下，那么这么多文件如何分布式存储呢？

	4. 如何让这个系统对用户来讲是透明的呢？（用户在终端上使用的时候的感觉和在一台电脑上使用的感觉是一样的）

	5. 这种存储的设计是分布式文件系统，而这种设计需要考虑软件，硬件，效率，灾难恢复等等多方面的问题以及多方面的知识，所以这不是一个简单的工程问题。

	6. Map-Reduce的map阶段就是把任务分配给不同的机器，分布式系统的机器性能都是不同的，而且即便机器性能相同，任务往往也不会分配的那么平均，这就必然导致有些机器先完成有些机器后完成，所以任务如何分配也需要考虑，负载均衡的策略也需要去设计。分布式系统是多用户的，任务的执行是并行的，这就需要跟踪每个任务的完成进度，一旦有的任务失败就要想方设法的重新执行该任务，所以就需要中心控制。而且既然要跟踪任务的执行，也需要实时查询节点的状态，同时还得重新分配失败的任务。

	7. 任何一个系统都要设置用户的权限，防止用户修改删除系统重要文件，导致系统崩溃，分布式系统也不例外。对多用户的权限控制也是要考虑的安全问题之一。

	8. 以上每个点都有可能成为大数据问题的考察点。

## Map-Reduce优势

* 对海量数据（亿级）的处理

* 处理数以百亿计的网页上的单词的处理

## 海量数据的常见处理技巧

1. 分而治之。通过哈希函数将大任务分流到不同的机器，或分流成小文件。在每一个小部分上进行处理，最终在将结果合并起来。

2. 这类题目经常用到HashMap或bitmap这类数据结构来做。

难点：通讯、时间和空间的估算。

## Map-Reduce的一些经典例题

1. 用Map-Reduce方法统计一篇文章中每个单词出现的个数

	1. 对文章进行预处理，去掉文章中所有的标点符号。

	2. 对连字符 '-' 的处理，如：pencil-box，单词在结尾处没写完，用连字符链接的情况。

	3. 对于缩写的处理，如：I'm, don't, It's, I'd like等等。

	4. 大小写的转换。

	5. 以上几步的目的就是为了把文章中的单词抓取出来

	6. map阶段：
		
		* 对每个单词生成词频为1的记录，如（dog,1），（pig,1），一个单词可能有多个词频为1的记录，此时还未进行合并。

		* 通过hash函数将所有单词分配成多个子任务（单词相同的记录会分配在一起）

	7. 在reduce阶段中，每一个子任务中相同单词的记录进行合并，生成一个记录，然后把所有记录返回就是整篇文章的词根统计了。

	8. 每个子任务都是并行处理的，所以就会节省时间

2. 请对10亿个IPV4的地址进行排序，每个ip只会出现一次

	1. IPV4的地址数量一共只有42亿多一点

	2. 可以用一个简单的规则将一个ip地址转换为一个无符号整数

	3. 普通的方法：将10亿个ip地址转换为整数，再对整数进行排序，排完序后再转回ip地址

	4. 一个ip地址相当于一个4字节的整数（int），空间约4G

	5. 申请长度为2的32次方的bit类型的数组。

	6. 每个位置上是一个bit，可以表示0或1两种状态。

	7. 长度为2的32次方的bit数组，空间约为几百M字节。

	8. 出现了某个数字就把bit数组上对应位置置为1。

	9. 10亿个ip分别放入bitmap中。

	10. 最后顺序遍历一遍bitmap，再把对应的数字转换为对应的ip地址即可。

3. 请对10亿人的年龄进行排序

	1. 可以认为年龄在0~200之间，10亿个数都在0~200之间。

	2. 用一个足够大的数组对10亿个人的年龄按照计数排序就可以。

	3. 按照桶排序的思想

4. 有一个包含20亿个全是32位整数的大文件，在其中找到出现次数最多的数，但是内存限制只有2G

	1. 方法一：使用hash表对每一个数做词频统计

	2. key表示一个数（int-4字节-32位）

	3. value表示该数出现的次数（20亿-32位-4字节）

	4. 一条记录8个字节

	5. 最坏的情况下：20亿*8字节 = 160亿字节 --> 16G（内存只有2G）

	6. 方法二：对大文件使用哈希函数进行分流，分成多个小文件

	7. 同一种数不会被分流到不同文件，这是哈希函数性质决定的

	8. 对于不同的数，每个文件中含有整数的种数几乎一样，这也是哈希函数性质决定的

	9. 然后对每一个小文件用哈希表来统计每种数出现的次数，这样就得到了每个小文件中各自出现次数最多的数，在从这16个数中选出出现次数最多的数字。

5. 32位无符号整数的范围是0~4294967295。现在有一个正好包含40亿个无符号整数的文件，所以在整个范围中必然有没有出现过的数。可以使用最多10M的内存，只用找到一个没出现过的数即可，该如何找？

	* 使用hashmap -> 所占内存空间过大 key -> 4字节 -> 40亿 -> 16G

	* 使用bitmap -> 2的32次方 -> 500M内存

	* 把这个bitmap数组划分成64个区间 -> 500/64 -> 小于10M内存

	* 2的32次方是42亿多，在各个区间进行统计的时候必然会出现某个区间统计的数字的个数小于区间大小的情况，只要找到了一个这样的区间，就可以知道在这个区间上肯定少了某个数。

	* 假设这个区间为a，所以我们只需要在这个区间a上遍历一遍通过bitmap统计该区间上出现的数的情况即可。

总结：

	1. 根据区间的性质，确定区间的大小，进而再去确定要分多少个区间

	2. 先算算给定限制的内存空间（比如说10M）内表示多大区间的bitmap

	3. 然后用2的32次方除以这个区间的大小来表示到底要分多少个区间

	4. 利用区间计数的方式找到那个计数不足的区间

	5. 利用这个区间上的数通过bitmap来进行词频统计

6. 某搜索公司一天的用户搜索词汇是海量的，假设有百亿的数据量，请设计一种求出每天最热100词的可行办法。

	* 通过hash分流的方式进行处理，对包含百亿数据量的文件分流到不同的机器上（具体多少台机器与面试官商量，内存限制，硬盘限制）

	* 如果词汇量依然很大，可以再通过哈希分流对每台机器上的文件在拆分成更小的文件进行处理

	* 每台机器之间并行的进行计算，一台机器上的多个文件可以通过多线程的方式并发的进行计算词频统计

	* 通过哈希表对每个小文件进行词频统计

	* 通过小根堆来对top100进行筛选

	* 再对一台机器上的所有小文件的top100进行筛选

	* 再对多台机器之间的文件再进行外排序或小根堆来获得总体的top100

	* hash分流 + 哈希表做词频统计 + 堆结构进行筛选
	
7. 工程师常使用服务器集群来设计和实现数据缓存，以下是常见策略。
	1. 无论是添加，查询还是删除数据，都先将数据的id通过哈希函数转换成一个哈希值，记为key。
	2. 如果目前机器有N台，则计算key%N的值，这个值就是该数据所属的机器编号，无论是添加、删除还是查询操作，都只在这台机器上进行。
	请分析这种缓存策略可能带来的问题，并提出改进方案。

潜在问题：如果增加或删除机器，数据迁移的代价很大。

解决：一致性哈希算法

* 数据id通过哈希值计算后的结果为0~2的32次方，把这些数据首尾相连构成一个闭合的环形。

* 一个数据id计算出哈希值之后可以对应到环中的一个位置上

* 一个机器id计算出哈希值之后也可以对应到环中的一个位置上

* 顺时针的找寻离这个数据最近的机器就是该数据的归属

* 在添加数据时的数据调整代价和数据迁移代价是比较小的，只需要调整相邻的顺时针方向上的数据即可，而如果不采用这种方法，就有可能存在大批量的数据迁移。

* 删除数据也是同样的道理，把数据顺时针的复制到下一台机器即可

## 大数据的一个特点

* 通过哈希函数不断的进行分流来解决内存限制或者其他限制的问题

* 通过hashmap

* 通过bitmap

* 如果bitmap所占用的空间过大，可以给bitmap划分成多个区间

